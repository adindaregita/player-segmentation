{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60d3cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divaoncom/Library/Python/3.10/lib/python/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/divaoncom/Library/Python/3.10/lib/python/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Load data embedding\n",
    "embedding_df = pd.read_csv(\"embedding_umap.csv\")\n",
    "\n",
    "# Ambil embedding kolom yang sesuai (bisa embedding_0, UMAP_1, UMAP_2, dst)\n",
    "X = embedding_df[['UMAP_1', 'UMAP_2']].values\n",
    "X = normalize(X)\n",
    "\n",
    "# Clustering\n",
    "clusterer = HDBSCAN(min_cluster_size=5)\n",
    "embedding_df['cluster'] = clusterer.fit_predict(X)\n",
    "\n",
    "# Simpan ulang hasil\n",
    "embedding_df.to_csv(\"embedding_umap_clustered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db706e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File berhasil disimpan sebagai 'game_top_topics_keywords.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 1: Load data\n",
    "# -----------------------------\n",
    "embedding_df = pd.read_csv(\"embedding_umap_clustered.csv\")        # berisi cleaned_Reviews dan cluster\n",
    "preprocessed_df = pd.read_csv(\"preprocessed_Reviews.csv\")         # berisi Game dan cleaned_Reviews\n",
    "topic_keywords_df = pd.read_csv(\"final_topic_keywordsv2.csv\")       # berisi cluster dan keywords (list/str)\n",
    "\n",
    "# Ubah kolom keywords ke list jika belum\n",
    "def parse_keywords(x):\n",
    "    if isinstance(x, str):\n",
    "        return eval(x) if x.startswith(\"[\") else x.split(\",\")\n",
    "    return x\n",
    "\n",
    "topic_keywords_df['keywords'] = topic_keywords_df['keywords'].apply(parse_keywords)\n",
    "\n",
    "# Buat mapping cluster -> keywords\n",
    "cluster_keywords_map = dict(zip(topic_keywords_df['cluster'], topic_keywords_df['keywords']))\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 2: Gabungkan cluster ke preprocessed_df\n",
    "# -----------------------------\n",
    "merged_df = pd.merge(preprocessed_df, embedding_df[['cleaned_Reviews', 'cluster']], \n",
    "                     on='cleaned_Reviews', how='left')\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 3: Buang noise (cluster = -1)\n",
    "# -----------------------------\n",
    "merged_df = merged_df[merged_df['cluster'] != -1]\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 4: Hitung jumlah game per cluster (untuk cari cluster umum)\n",
    "# -----------------------------\n",
    "game_per_cluster = merged_df.groupby('cluster')['Game'].nunique()\n",
    "threshold = 0.10 * merged_df['Game'].nunique()  # misal: >10% game\n",
    "common_clusters = game_per_cluster[game_per_cluster > threshold].index.tolist()\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 5: Hitung topik dominan per game (tanpa common clusters)\n",
    "# -----------------------------\n",
    "topic_per_game = merged_df[~merged_df['cluster'].isin(common_clusters)] \\\n",
    "    .groupby(['Game', 'cluster']) \\\n",
    "    .size().reset_index(name='count')\n",
    "\n",
    "top_topics = topic_per_game.sort_values(['Game', 'count'], ascending=[True, False])\n",
    "top_topics = top_topics.groupby('Game').head(3)\n",
    "\n",
    "# Gabungkan list cluster per game\n",
    "top_topics_agg = top_topics.groupby('Game')['cluster'].apply(list).reset_index()\n",
    "top_topics_agg.columns = ['Game', 'Top_Clusters']\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 6: Mapping ke keywords\n",
    "# -----------------------------\n",
    "def map_clusters_to_keywords(cluster_list, keyword_map):\n",
    "    return [keyword_map[c] for c in cluster_list if c in keyword_map]\n",
    "\n",
    "top_topics_agg['Top_Topic_Keywords'] = top_topics_agg['Top_Clusters'].apply(\n",
    "    lambda cl: map_clusters_to_keywords(cl, cluster_keywords_map)\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 7: Simpan ke CSV\n",
    "# -----------------------------\n",
    "top_topics_agg.to_csv(\"game_top_topics_keywords.csv\", index=False)\n",
    "print(\"✅ File berhasil disimpan sebagai 'game_top_topics_keywords.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
