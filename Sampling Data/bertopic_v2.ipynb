{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0051feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>cleaned_Reviews</th>\n",
       "      <th>num_words</th>\n",
       "      <th>review_length</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>UMAP_1</th>\n",
       "      <th>UMAP_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACE COMBAT™ 7: SKIES UNKNOWN</td>\n",
       "      <td>major negative story character lame everything...</td>\n",
       "      <td>19</td>\n",
       "      <td>134</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>17.112667</td>\n",
       "      <td>5.819002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACE COMBAT™ 7: SKIES UNKNOWN</td>\n",
       "      <td>meh big meh bland storyline japanese melodrama...</td>\n",
       "      <td>28</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.003744</td>\n",
       "      <td>18.612220</td>\n",
       "      <td>6.726864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACE COMBAT™ 7: SKIES UNKNOWN</td>\n",
       "      <td>honestly insane I use play ace combat game ps ...</td>\n",
       "      <td>94</td>\n",
       "      <td>601</td>\n",
       "      <td>0.024339</td>\n",
       "      <td>19.020710</td>\n",
       "      <td>5.985852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACE COMBAT™ 7: SKIES UNKNOWN</td>\n",
       "      <td>I never play anything series one fun dogfighti...</td>\n",
       "      <td>25</td>\n",
       "      <td>162</td>\n",
       "      <td>-0.047841</td>\n",
       "      <td>18.525732</td>\n",
       "      <td>6.311223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACE COMBAT™ 7: SKIES UNKNOWN</td>\n",
       "      <td>I highway danger zone</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>16.138220</td>\n",
       "      <td>5.633336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Game  \\\n",
       "0  ACE COMBAT™ 7: SKIES UNKNOWN   \n",
       "1  ACE COMBAT™ 7: SKIES UNKNOWN   \n",
       "2  ACE COMBAT™ 7: SKIES UNKNOWN   \n",
       "3  ACE COMBAT™ 7: SKIES UNKNOWN   \n",
       "4  ACE COMBAT™ 7: SKIES UNKNOWN   \n",
       "\n",
       "                                     cleaned_Reviews  num_words  \\\n",
       "0  major negative story character lame everything...         19   \n",
       "1  meh big meh bland storyline japanese melodrama...         28   \n",
       "2  honestly insane I use play ace combat game ps ...         94   \n",
       "3  I never play anything series one fun dogfighti...         25   \n",
       "4                              I highway danger zone          4   \n",
       "\n",
       "   review_length  embedding_0     UMAP_1    UMAP_2  \n",
       "0            134     0.013184  17.112667  5.819002  \n",
       "1            178    -0.003744  18.612220  6.726864  \n",
       "2            601     0.024339  19.020710  5.985852  \n",
       "3            162    -0.047841  18.525732  6.311223  \n",
       "4             21     0.013516  16.138220  5.633336  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from umap import UMAP\n",
    "import hdbscan\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data hasil embedding + preprocessing review\n",
    "embedding_df = pd.read_csv('embedding_umap.csv')  # Sesuaikan nama jika berbeda\n",
    "\n",
    "# Cek kolom\n",
    "embedding_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df59122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divaoncom/Library/Python/3.10/lib/python/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/divaoncom/Library/Python/3.10/lib/python/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "-1     157\n",
       " 3      19\n",
       " 0      17\n",
       " 7      16\n",
       " 16     16\n",
       " 5      14\n",
       " 11     13\n",
       " 8      12\n",
       " 14     12\n",
       " 12     10\n",
       " 2       9\n",
       " 10      9\n",
       " 1       9\n",
       " 6       9\n",
       " 17      9\n",
       " 13      7\n",
       " 15      7\n",
       " 4       6\n",
       " 9       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ambil kolom untuk clustering (biasanya hasil UMAP, misalnya: ['x', 'y'])\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5)\n",
    "embedding_df['cluster'] = clusterer.fit_predict(embedding_df[['UMAP_1', 'UMAP_2']])\n",
    "embedding_df['cluster'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9f99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/7d1scz1n2f7gnm2sy2q4rgs00000gn/T/ipykernel_17525/1490675003.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_df['cleaned_Reviews'] = valid_df['cleaned_Reviews'].fillna('').astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>abertura</th>\n",
       "      <th>ability</th>\n",
       "      <th>abillity</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abysmally</th>\n",
       "      <th>ac</th>\n",
       "      <th>accepted</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yup</th>\n",
       "      <th>zb</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroeffort</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  abertura  ability  abillity  able  absolute  absolutely  abysmally  \\\n",
       "0  0.0       0.0      0.0       0.0   0.0       0.0         0.0        0.0   \n",
       "1  0.0       0.0      0.0       0.0   0.0       0.0         0.0        0.0   \n",
       "2  0.0       0.0      0.0       0.0   0.0       0.0         0.0        0.0   \n",
       "3  0.0       0.0      0.0       0.0   0.0       0.0         0.0        0.0   \n",
       "4  0.0       0.0      0.0       0.0   0.0       0.0         0.0        0.0   \n",
       "\n",
       "    ac  accepted  ...  young  youtube   yr       yup   zb  zero  zeroeffort  \\\n",
       "0  0.0       0.0  ...    0.0      0.0  0.0  2.197225  0.0   0.0         0.0   \n",
       "1  0.0       0.0  ...    0.0      0.0  0.0  0.000000  0.0   0.0         0.0   \n",
       "2  0.0       0.0  ...    0.0      0.0  0.0  0.000000  0.0   0.0         0.0   \n",
       "3  0.0       0.0  ...    0.0      0.0  0.0  0.000000  0.0   0.0         0.0   \n",
       "4  0.0       0.0  ...    0.0      0.0  0.0  0.000000  0.0   0.0         0.0   \n",
       "\n",
       "   zombie  zoom   zu  \n",
       "0     0.0   0.0  0.0  \n",
       "1     0.0   0.0  0.0  \n",
       "2     0.0   0.0  0.0  \n",
       "3     0.0   0.0  0.0  \n",
       "4     0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 2363 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Filter hanya cluster valid (selain -1)\n",
    "valid_df = embedding_df[embedding_df['cluster'] != -1]\n",
    "\n",
    "# Pastikan kolom cleaned_Reviews bertipe string dan tidak mengandung NaN\n",
    "valid_df['cleaned_Reviews'] = valid_df['cleaned_Reviews'].fillna('').astype(str)\n",
    "\n",
    "# Gabungkan review dalam tiap cluster\n",
    "docs_per_topic = valid_df.groupby('cluster')['cleaned_Reviews'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# TF Count\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs_per_topic['cleaned_Reviews'])\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Fungsi perhitungan c-TF-IDF\n",
    "def compute_ctfidf(X, m):\n",
    "    df = np.diff(X.tocsc().indptr)\n",
    "    idf = np.log(m / (1 + df))\n",
    "    ctfidf = X.multiply(idf)\n",
    "    return ctfidf\n",
    "\n",
    "# Hitung c-TF-IDF\n",
    "m = len(docs_per_topic)\n",
    "ctfidf = compute_ctfidf(X, m)\n",
    "ctfidf_array = ctfidf.toarray()\n",
    "\n",
    "# Buat DataFrame hasil c-TF-IDF\n",
    "ctfidf_df = pd.DataFrame(ctfidf_array, columns=words)\n",
    "ctfidf_df['cluster'] = docs_per_topic['cluster']\n",
    "ctfidf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e06109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: ['woooooooooooooooo',\n",
       "  'underrated',\n",
       "  'goody',\n",
       "  'yup',\n",
       "  'among',\n",
       "  'neat',\n",
       "  'rip',\n",
       "  'meh',\n",
       "  'yet',\n",
       "  'awesome'],\n",
       " 1.0: ['horny',\n",
       "  'depressed',\n",
       "  'freakin',\n",
       "  'ludicrous',\n",
       "  'ass',\n",
       "  'bore',\n",
       "  'max',\n",
       "  'laugh',\n",
       "  'tedious',\n",
       "  'fun'],\n",
       " 2.0: ['shooter',\n",
       "  'soul',\n",
       "  'fragile',\n",
       "  'base',\n",
       "  'hunting',\n",
       "  'gun',\n",
       "  'devil',\n",
       "  'chad',\n",
       "  'paranoid',\n",
       "  'onward'],\n",
       " 3.0: ['game',\n",
       "  'break',\n",
       "  'perfec',\n",
       "  'starve',\n",
       "  'cow',\n",
       "  'gr',\n",
       "  'beeg',\n",
       "  'chinese',\n",
       "  'duck',\n",
       "  'cheater'],\n",
       " 4.0: ['jep',\n",
       "  'outlast',\n",
       "  'frog',\n",
       "  'count',\n",
       "  'breadman',\n",
       "  'bean',\n",
       "  'bore',\n",
       "  'know',\n",
       "  'well',\n",
       "  'primarily'],\n",
       " 5.0: ['crash',\n",
       "  'choppy',\n",
       "  'cpu',\n",
       "  'screen',\n",
       "  'file',\n",
       "  'problem',\n",
       "  'customer',\n",
       "  'desktop',\n",
       "  'answer',\n",
       "  'gb'],\n",
       " 6.0: ['duty',\n",
       "  'battlefield',\n",
       "  'cod',\n",
       "  'ea',\n",
       "  'ace',\n",
       "  'series',\n",
       "  'game',\n",
       "  'steam',\n",
       "  'technical',\n",
       "  'launch'],\n",
       " 7.0: ['enemy',\n",
       "  'marine',\n",
       "  'army',\n",
       "  'game',\n",
       "  'character',\n",
       "  'feel',\n",
       "  'space',\n",
       "  'unit',\n",
       "  'tech',\n",
       "  'system'],\n",
       " 8.0: ['multiplayer',\n",
       "  'buy',\n",
       "  'bundle',\n",
       "  'price',\n",
       "  'worth',\n",
       "  'interest',\n",
       "  'might',\n",
       "  'ever',\n",
       "  'around',\n",
       "  'online'],\n",
       " 9.0: ['fov',\n",
       "  'ad',\n",
       "  'download',\n",
       "  'please',\n",
       "  'liveservice',\n",
       "  'titanfall',\n",
       "  'trap',\n",
       "  'brilliant',\n",
       "  'mindless',\n",
       "  'pleaseplaymeforever'],\n",
       " 10.0: ['steep',\n",
       "  'moment',\n",
       "  'warhammer',\n",
       "  'tactical',\n",
       "  'war',\n",
       "  'character',\n",
       "  'fp',\n",
       "  'inject',\n",
       "  'wwii',\n",
       "  'addictive'],\n",
       " 11.0: ['card',\n",
       "  'deck',\n",
       "  'use',\n",
       "  'deckbuilder',\n",
       "  'scenario',\n",
       "  'various',\n",
       "  'slot',\n",
       "  'item',\n",
       "  'mechanic',\n",
       "  'hand'],\n",
       " 12.0: ['coop',\n",
       "  'character',\n",
       "  'strategy',\n",
       "  'variety',\n",
       "  'gow',\n",
       "  'challenge',\n",
       "  'scale',\n",
       "  'con',\n",
       "  'really',\n",
       "  'fun'],\n",
       " 13.0: ['nicht',\n",
       "  'de',\n",
       "  'que',\n",
       "  'da',\n",
       "  'se',\n",
       "  'das',\n",
       "  'um',\n",
       "  'minha',\n",
       "  'man',\n",
       "  'jedoch'],\n",
       " 14.0: ['overly',\n",
       "  'voice',\n",
       "  'wait',\n",
       "  'game',\n",
       "  'especially',\n",
       "  'feel',\n",
       "  'bad',\n",
       "  'act',\n",
       "  'matter',\n",
       "  'bother'],\n",
       " 15.0: ['wolfenstein',\n",
       "  'order',\n",
       "  'castle',\n",
       "  'nazi',\n",
       "  'new',\n",
       "  'blood',\n",
       "  'return',\n",
       "  'horror',\n",
       "  'say',\n",
       "  'assault'],\n",
       " 16.0: ['equipment',\n",
       "  'space',\n",
       "  'coop',\n",
       "  'boardgame',\n",
       "  'throw',\n",
       "  'game',\n",
       "  'really',\n",
       "  'unlock',\n",
       "  'level',\n",
       "  'map'],\n",
       " 17.0: ['metal',\n",
       "  'horror',\n",
       "  'bring',\n",
       "  'wilson',\n",
       "  'emotionally',\n",
       "  'gear',\n",
       "  'masterpiece',\n",
       "  'solid',\n",
       "  'also',\n",
       "  'ever']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ambil 10 kata kunci teratas untuk tiap cluster\n",
    "top_k = 10\n",
    "top_keywords = {}\n",
    "\n",
    "for i, row in ctfidf_df.iterrows():\n",
    "    cluster = row['cluster']\n",
    "    row = row.drop('cluster')\n",
    "    top_words = row.sort_values(ascending=False).head(top_k).index.tolist()\n",
    "    top_keywords[cluster] = top_words\n",
    "\n",
    "# Lihat hasil\n",
    "top_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c0e67bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load model embedding (bisa diganti sesuai model BERT yang kamu pakai)\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Fungsi MMR\n",
    "def mmr(doc_embedding, word_embeddings, words, top_n, diversity):\n",
    "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding.reshape(1, -1))\n",
    "    word_similarity = cosine_similarity(word_embeddings)\n",
    "\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    for _ in range(top_n - 1):\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "        mmr_dist = (1 - diversity) * candidate_similarities.reshape(-1) - diversity * target_similarities\n",
    "        next_idx = candidates_idx[np.argmax(mmr_dist)]\n",
    "        keywords_idx.append(next_idx)\n",
    "        candidates_idx.remove(next_idx)\n",
    "\n",
    "    return [words[i] for i in keywords_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7d16a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[good, primaris, price, underrated, yup]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[stuff, ludicrous, quite, bore, physics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[gun, ah, onward, base, chad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[game, perfec, wait, cow, chinese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[previous, prestigious, breadman, well, frog]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                       keywords\n",
       "0      0.0       [good, primaris, price, underrated, yup]\n",
       "1      1.0       [stuff, ludicrous, quite, bore, physics]\n",
       "2      2.0                  [gun, ah, onward, base, chad]\n",
       "3      3.0             [game, perfec, wait, cow, chinese]\n",
       "4      4.0  [previous, prestigious, breadman, well, frog]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simpan hasil akhir MMR per cluster\n",
    "final_keywords = []\n",
    "\n",
    "for i, row in ctfidf_df.iterrows():\n",
    "    cluster = row['cluster']\n",
    "    row = row.drop('cluster')\n",
    "    \n",
    "    # Ambil 20 kata dengan skor c-TF-IDF tertinggi\n",
    "    top_words = row.sort_values(ascending=False).head(20)\n",
    "    words = top_words.index.tolist()\n",
    "    scores = top_words.values.tolist()\n",
    "\n",
    "    # Buat embedding kata dan cluster\n",
    "    word_embeddings = embedder.encode(words, convert_to_tensor=False)\n",
    "    topic_embedding = np.mean(word_embeddings, axis=0)\n",
    "\n",
    "    # Jalankan MMR\n",
    "    selected_keywords = mmr(\n",
    "        doc_embedding=topic_embedding,\n",
    "        word_embeddings=word_embeddings,\n",
    "        words=words,\n",
    "        top_n=5,\n",
    "        diversity=0.7\n",
    "    )\n",
    "\n",
    "    final_keywords.append({'cluster': cluster, 'keywords': selected_keywords})\n",
    "\n",
    "# Konversi ke DataFrame\n",
    "mmr_keywords_df = pd.DataFrame(final_keywords)\n",
    "mmr_keywords_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6fb180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cluster                                           keywords\n",
      "0       0.0           [good, primaris, price, underrated, yup]\n",
      "1       1.0           [stuff, ludicrous, quite, bore, physics]\n",
      "2       2.0                      [gun, ah, onward, base, chad]\n",
      "3       3.0                 [game, perfec, wait, cow, chinese]\n",
      "4       4.0      [previous, prestigious, breadman, well, frog]\n",
      "5       5.0   [problem, disapear, desktop, expedition, choppy]\n",
      "6       6.0    [game, amazing, consistent, technical, texture]\n",
      "7       7.0         [character, army, since, problem, another]\n",
      "8       8.0  [sale, ever, boooooooooooooooooooooooooooooooo...\n",
      "9       9.0  [trash, modernwarfare, please, publisher, hacker]\n",
      "10     10.0            [war, noticeably, masculine, addon, fp]\n",
      "11     11.0            [card, outside, clever, scenario, turn]\n",
      "12     12.0                  [beat, loot, coop, really, color]\n",
      "13     13.0                          [das, srie, man, se, uma]\n",
      "14     14.0             [emotional, wait, blake, hour, review]\n",
      "15     15.0          [horror, dualwielde, return, means, soak]\n",
      "16     16.0                [game, would, equipment, es, space]\n",
      "17     17.0               [movie, eghhh, amazing, solid, ever]\n"
     ]
    }
   ],
   "source": [
    "# Contoh output\n",
    "print(mmr_keywords_df)\n",
    "\n",
    "# Simpan jika perlu\n",
    "mmr_keywords_df.to_csv(\"final_topic_keywords.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb894440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping English labels\n",
    "df = pd.read_csv(\"final_topic_keywords.csv\")\n",
    "topic_labels_en = {\n",
    "    0: \"Underrated games with good value\",\n",
    "    1: \"Weird physics and boring gameplay\",\n",
    "    2: \"Military/FPS games with weapons and tactics\",\n",
    "    3: \"Anticipation for release/update (China)\",\n",
    "    4: \"Internal references or specific developers\",\n",
    "    5: \"Technical bugs and poor performance\",\n",
    "    6: \"Positive graphics and technical performance\",\n",
    "    7: \"Problematic characters\",\n",
    "    8: \"Disappointment after discounted purchase\",\n",
    "    9: \"Frustration with cheaters and publishers\",\n",
    "    10: \"War themes and DLC\",\n",
    "    11: \"Strategy games\",\n",
    "    12: \"Co-op and loot system\",\n",
    "    13: \"Non-English reviews\",\n",
    "    14: \"Emotional narrative-driven games\",\n",
    "    15: \"Horror, dual-wield, dark atmosphere\",\n",
    "    16: \"Sci-fi games with outer space theme\",\n",
    "    17: \"Cinematic games like movies\"\n",
    "}\n",
    "\n",
    "# Tambahkan kolom baru ke DataFrame\n",
    "df['topic_label_en'] = df['cluster'].map(topic_labels_en)\n",
    "\n",
    "# Simpan ke file baru\n",
    "df.to_csv(\"final_topic_keywords.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc27081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Coherence Score (c_v): 0.6503\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Unduh tokenizer NLTK jika belum tersedia\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenisasi dokumen gabungan per topik (hasil dari docs_per_topic)\n",
    "tokenized_topics = [word_tokenize(doc.lower()) for doc in docs_per_topic['cleaned_Reviews']]\n",
    "\n",
    "# Buat dictionary dan corpus untuk Gensim\n",
    "dictionary = Dictionary(tokenized_topics)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_topics]\n",
    "\n",
    "# Ambil top-N kata dari c-TF-IDF untuk masing-masing topik\n",
    "top_n = 10  # kamu bisa sesuaikan nilainya\n",
    "top_words_per_topic = []\n",
    "for idx, row in ctfidf_df.drop(columns=['cluster']).iterrows():\n",
    "    sorted_words = row.sort_values(ascending=False)\n",
    "    top_words = sorted_words.head(top_n).index.tolist()\n",
    "    top_words_per_topic.append(top_words)\n",
    "\n",
    "# Hitung coherence score menggunakan metric 'c_v'\n",
    "coherence_model = CoherenceModel(\n",
    "    topics=top_words_per_topic,\n",
    "    texts=tokenized_topics,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ")\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(f\"Topic Coherence Score (c_v): {coherence_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
